{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e1aaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "df = pd.read_csv('jobs_jd.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f077e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_text = \"\"\"active-\n",
    "adventurous-\n",
    "aggress-\n",
    "ambitio-\n",
    "analy-\n",
    "assert-\n",
    "athlet-\n",
    "autonom-\n",
    "battle-\n",
    "boast-\n",
    "challeng-\n",
    "champion-\n",
    "compet-\n",
    "confident-\n",
    "courag-\n",
    "decid-\n",
    "decision-\n",
    "decisive-\n",
    "defend-\n",
    "determin-\n",
    "domina-\n",
    "dominant-\n",
    "driven-\n",
    "fearless-\n",
    "fight-\n",
    "force-\n",
    "greedy-\n",
    "head-strong-\n",
    "headstrong-\n",
    "hierarch-\n",
    "hostil-\n",
    "impulsive-\n",
    "independen-\n",
    "individual-\n",
    "intellect-\n",
    "lead-\n",
    "logic-\n",
    "objective-\n",
    "opinion-\n",
    "outspoken-\n",
    "persist-\n",
    "principle-\n",
    "reckless-\n",
    "self-confiden-\n",
    "self-relian-\n",
    "self-sufficien-\n",
    "selfconfiden-\n",
    "selfrelian-\n",
    "selfsufficien-\n",
    "stubborn-\n",
    "superior-\n",
    "unreasonab-\n",
    "agree-\n",
    "affectionate-\n",
    "child-\n",
    "cheer-\n",
    "collab-\n",
    "commit-\n",
    "communal-\n",
    "compassion-\n",
    "connect-\n",
    "considerate-\n",
    "cooperat-\n",
    "co-operat-\n",
    "depend-\n",
    "emotiona-\n",
    "empath-\n",
    "feel-\n",
    "flatterable-\n",
    "gentle-\n",
    "honest-\n",
    "interpersonal-\n",
    "interdependen-\n",
    "interpersona-\n",
    "inter-personal-\n",
    "inter-dependen-\n",
    "inter-persona-\n",
    "kind-\n",
    "kinship-\n",
    "loyal-\n",
    "modesty-\n",
    "nag-\n",
    "nurtur-\n",
    "pleasant-\n",
    "polite-\n",
    "quiet-\n",
    "respon-\n",
    "sensitiv-\n",
    "submissive-\n",
    "support-\n",
    "sympath-\n",
    "tender-\n",
    "together-\n",
    "trust-\n",
    "understand-\n",
    "warm-\n",
    "whin-\n",
    "enthusias-\n",
    "inclusive-\n",
    "yield-\n",
    "share-\n",
    "sharin-\"\"\"\n",
    "\n",
    "stems = [s.strip('-').lower() for s in stem_text.strip().split('\\n') if s.strip()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19821de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", output_attentions=True)\n",
    "model.eval()\n",
    "\n",
    "def extract_stem_attention(texts, stem_list):\n",
    "    stem_attention = defaultdict(list)\n",
    "\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "        attentions = outputs.attentions[-1].mean(dim=1).squeeze(0)  # shape: [seq_len, seq_len]\n",
    "\n",
    "        for i, token in enumerate(tokens):\n",
    "            clean_token = token.replace(\"##\", \"\").lower()\n",
    "            for stem in stem_list:\n",
    "                if stem in clean_token:\n",
    "                    score = attentions[:, i].mean().item()\n",
    "                    stem_attention[stem].append(score)\n",
    "\n",
    "    return stem_attention\n",
    "\n",
    "high_texts = df[df[\"women_proportion\"] >= 0.5][\"description\"].tolist()\n",
    "low_texts = df[df[\"women_proportion\"] < 0.5][\"description\"].tolist()\n",
    "\n",
    "high_scores = extract_stem_attention(high_texts, stems)\n",
    "low_scores = extract_stem_attention(low_texts, stems)\n",
    "\n",
    "high_avg = {stem: sum(scores) / len(scores) for stem, scores in high_scores.items() if len(scores) > 0}\n",
    "low_avg = {stem: sum(scores) / len(scores) for stem, scores in low_scores.items() if len(scores) > 0}\n",
    "\n",
    "attention_diff = {\n",
    "    stem: high_avg.get(stem, 0) - low_avg.get(stem, 0)\n",
    "    for stem in stems\n",
    "}\n",
    "\n",
    "diff_df = pd.DataFrame([\n",
    "    {\n",
    "        \"Stem\": stem,\n",
    "        \"High Avg Attention\": high_avg.get(stem, 0),\n",
    "        \"Low Avg Attention\": low_avg.get(stem, 0),\n",
    "        \"High - Low Attention Δ\": diff\n",
    "    }\n",
    "    for stem, diff in attention_diff.items()\n",
    "])\n",
    "\n",
    "diff_df = diff_df.sort_values(by=\"High - Low Attention Δ\", ascending=True)\n",
    "\n",
    "diff_df.to_csv(\"bert_attention_diff_sorted.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
